{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk-19\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\Program Files\\spark-3.5.3-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField,IntegerType,DateType,StringType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkSession.builder.appName(\"Word Count\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating schema for a sales_df data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"product_ID\",IntegerType(),True),\n",
    "    StructField(\"customer_ID\",StringType() , True),\n",
    "    StructField(\"order_date\",DateType(),True),\n",
    "    StructField(\"location\",StringType(),True),\n",
    "    StructField(\"source_order\",StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting data into the sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sc.read.format(\"csv\").option(\"inferschema\",\"true\").schema(schema).load(r\"C:\\Users\\rahul dodda\\Downloads\\sales.csv.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of display for sales_df data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[product_ID: int, customer_ID: string, order_date: date, location: string, source_order: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(sales_df))\n",
    "print(display(sales_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+--------+------------+\n",
      "|product_ID|customer_ID|order_date|location|source_order|\n",
      "+----------+-----------+----------+--------+------------+\n",
      "|         1|          A|2023-01-01|   India|      Swiggy|\n",
      "|         2|          A|2022-01-01|   India|      Swiggy|\n",
      "|         2|          A|2023-01-07|   India|      Swiggy|\n",
      "|         3|          A|2023-01-10|   India|  Restaurant|\n",
      "|         3|          A|2022-01-11|   India|      Swiggy|\n",
      "|         3|          A|2023-01-11|   India|  Restaurant|\n",
      "|         2|          B|2022-02-01|   India|      Swiggy|\n",
      "|         2|          B|2023-01-02|   India|      Swiggy|\n",
      "|         1|          B|2023-01-04|   India|  Restaurant|\n",
      "|         1|          B|2023-02-11|   India|      Swiggy|\n",
      "|         3|          B|2023-01-16|   India|      zomato|\n",
      "|         3|          B|2022-02-01|   India|      zomato|\n",
      "|         3|          C|2023-01-01|   India|      zomato|\n",
      "|         1|          C|2023-01-01|      UK|      Swiggy|\n",
      "|         6|          C|2022-01-07|      UK|      zomato|\n",
      "|         3|          D|2023-02-16|      UK|  Restaurant|\n",
      "|         5|          D|2022-02-01|      UK|      zomato|\n",
      "|         3|          E|2023-02-01|      UK|  Restaurant|\n",
      "|         4|          E|2023-02-01|      UK|      Swiggy|\n",
      "|         4|          E|2023-02-07|      UK|  Restaurant|\n",
      "+----------+-----------+----------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding columns to the sales_df and using year, month, quarter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+--------+------------+----------+-----------+-------------+\n",
      "|product_ID|customer_ID|order_date|location|source_order|order_year|order_month|order_quarter|\n",
      "+----------+-----------+----------+--------+------------+----------+-----------+-------------+\n",
      "|         1|          A|2023-01-01|   India|      Swiggy|      2023|          1|            1|\n",
      "|         2|          A|2022-01-01|   India|      Swiggy|      2022|          1|            1|\n",
      "|         2|          A|2023-01-07|   India|      Swiggy|      2023|          1|            1|\n",
      "|         3|          A|2023-01-10|   India|  Restaurant|      2023|          1|            1|\n",
      "|         3|          A|2022-01-11|   India|      Swiggy|      2022|          1|            1|\n",
      "|         3|          A|2023-01-11|   India|  Restaurant|      2023|          1|            1|\n",
      "|         2|          B|2022-02-01|   India|      Swiggy|      2022|          2|            1|\n",
      "|         2|          B|2023-01-02|   India|      Swiggy|      2023|          1|            1|\n",
      "|         1|          B|2023-01-04|   India|  Restaurant|      2023|          1|            1|\n",
      "|         1|          B|2023-02-11|   India|      Swiggy|      2023|          2|            1|\n",
      "|         3|          B|2023-01-16|   India|      zomato|      2023|          1|            1|\n",
      "|         3|          B|2022-02-01|   India|      zomato|      2022|          2|            1|\n",
      "|         3|          C|2023-01-01|   India|      zomato|      2023|          1|            1|\n",
      "|         1|          C|2023-01-01|      UK|      Swiggy|      2023|          1|            1|\n",
      "|         6|          C|2022-01-07|      UK|      zomato|      2022|          1|            1|\n",
      "|         3|          D|2023-02-16|      UK|  Restaurant|      2023|          2|            1|\n",
      "|         5|          D|2022-02-01|      UK|      zomato|      2022|          2|            1|\n",
      "|         3|          E|2023-02-01|      UK|  Restaurant|      2023|          2|            1|\n",
      "|         4|          E|2023-02-01|      UK|      Swiggy|      2023|          2|            1|\n",
      "|         4|          E|2023-02-07|      UK|  Restaurant|      2023|          2|            1|\n",
      "+----------+-----------+----------+--------+------------+----------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year,month,quarter\n",
    "\n",
    "sales_df = sales_df.withColumn(\"order_year\", year(sales_df.order_date))\n",
    "sales_df = sales_df.withColumn(\"order_month\", month(sales_df.order_date))\n",
    "sales_df = sales_df.withColumn(\"order_quarter\", quarter(sales_df.order_date))\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating menu_df schema and insert data into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+\n",
      "|product_ID|product_name|price|\n",
      "+----------+------------+-----+\n",
      "|         1|       PIZZA|  100|\n",
      "|         2|     Chowmin|  150|\n",
      "|         3|    sandwich|  120|\n",
      "|         4|        Dosa|  110|\n",
      "|         5|     Biryani|   80|\n",
      "|         6|       Pasta|  180|\n",
      "+----------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField,StructType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"product_ID\",IntegerType(),True),\n",
    "    StructField(\"product_name\",StringType(),True),\n",
    "    StructField(\"price\",StringType(),True)\n",
    "    \n",
    "])\n",
    "menu_df = sc.read.format(\"csv\").option(\"inferschema\",\"true\").schema(schema).load(r\"C:\\Users\\rahul dodda\\Downloads\\menu.csv.txt\")\n",
    "menu_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total amount spent by each customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|customer_id|sum(price)|\n",
      "+-----------+----------+\n",
      "|          A|    4260.0|\n",
      "|          B|    4440.0|\n",
      "|          C|    2400.0|\n",
      "|          D|    1200.0|\n",
      "|          E|    2040.0|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amount_spent = (sales_df.join(menu_df,'product_ID').groupby(\"customer_id\").agg({'price':'sum'})).orderBy(\"customer_id\")\n",
    "amount_spent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total amount spent on each food item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|product_name|sum(price)|\n",
      "+------------+----------+\n",
      "|       Pasta|    1080.0|\n",
      "|       PIZZA|    2100.0|\n",
      "|    sandwich|    5760.0|\n",
      "|     Biryani|     480.0|\n",
      "|     Chowmin|    3600.0|\n",
      "|        Dosa|    1320.0|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_spent = (sales_df.join(menu_df,'product_ID').groupby(\"product_name\").agg({'price':'sum'}))\n",
    "product_spent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total amount of sales in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|order_month|sum(price)|\n",
      "+-----------+----------+\n",
      "|          1|    2960.0|\n",
      "|          6|    2960.0|\n",
      "|          3|     910.0|\n",
      "|          5|    2960.0|\n",
      "|          7|     910.0|\n",
      "|         11|     910.0|\n",
      "|          2|    2730.0|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "month_spent = (sales_df.join(menu_df,'product_ID').groupby(\"order_month\").agg({'price':'sum'}))\n",
    "month_spent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yearly sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|order_year|sum(price)|\n",
      "+----------+----------+\n",
      "|      2023|    9990.0|\n",
      "|      2022|    4350.0|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "year_spent = (sales_df.join(menu_df,'product_ID').groupby(\"order_year\").agg({'price':'sum'}))\n",
    "year_spent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quaterly sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|order_quarter|sum(price)|\n",
      "+-------------+----------+\n",
      "|            1|    6600.0|\n",
      "|            3|     910.0|\n",
      "|            4|     910.0|\n",
      "|            2|    5920.0|\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quarter_spent = (sales_df.join(menu_df,'product_ID').groupby(\"order_quarter\").agg({'price':'sum'}))\n",
    "quarter_spent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total no of orders by each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|product_name|count(price)|\n",
      "+------------+------------+\n",
      "|       Pasta|           6|\n",
      "|       PIZZA|          21|\n",
      "|    sandwich|          48|\n",
      "|     Biryani|           6|\n",
      "|     Chowmin|          24|\n",
      "|        Dosa|          12|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_sold = (sales_df.join(menu_df,'product_ID').groupby(\"product_name\").agg({'price':'count'}))\n",
    "product_sold.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top 5 ordered items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+\n",
      "|product_name|product_count|\n",
      "+------------+-------------+\n",
      "|    sandwich|           48|\n",
      "|     Chowmin|           24|\n",
      "|       PIZZA|           21|\n",
      "|        Dosa|           12|\n",
      "|       Pasta|            6|\n",
      "+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "product_sold = (sales_df.join(menu_df,'product_ID').groupby(\"product_name\")\n",
    "                .agg(count('product_id').alias(\"product_count\"))\n",
    "                .orderBy(\"product_count\",ascending=0)\n",
    "                .limit(5))\n",
    "product_sold.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top ordered items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+\n",
      "|product_name|product_count|\n",
      "+------------+-------------+\n",
      "|    sandwich|           48|\n",
      "+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "product_sold = (sales_df.join(menu_df,'product_ID').groupby(\"product_name\")\n",
    "                .agg(count('product_id').alias(\"product_count\"))\n",
    "                .orderBy(\"product_count\",ascending=0)\n",
    "                .limit(1))\n",
    "product_sold.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frequency of customer visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|customer_id|visits|\n",
      "+-----------+------+\n",
      "|          E|     5|\n",
      "|          B|     6|\n",
      "|          D|     1|\n",
      "|          C|     3|\n",
      "|          A|     6|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "pdf = (sales_df.filter(sales_df.source_order == \"Restaurant\").groupBy('customer_id').agg(countDistinct('order_date').alias(\"visits\")))\n",
    "pdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total sales by each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|location|sum(price)|\n",
      "+--------+----------+\n",
      "|   India|    4860.0|\n",
      "|     USA|    2460.0|\n",
      "|      UK|    7020.0|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amount_spent = (sales_df.join(menu_df,'product_ID').groupby(\"location\").agg({'price':'sum'}))\n",
    "amount_spent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total sales by order_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|source_order|sum(price)|\n",
      "+------------+----------+\n",
      "|      zomato|    4810.0|\n",
      "|      Swiggy|    6330.0|\n",
      "|  Restaurant|    3090.0|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amount_spent = (sales_df.join(menu_df,'product_ID').groupby(\"source_order\").agg({'price':'sum'}).limit(3))\n",
    "amount_spent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
